# streamlit_mbti_images_robust.py
import streamlit as st
import urllib.parse
import urllib.request
import json
from typing import Optional

st.set_page_config(page_title="MBTI ì¶”ì²œ (ì´ë¯¸ì§€ ê°œì„ íŒ)", layout="centered")
st.title("ğŸ“šğŸ¬ MBTIë³„ ë„ì„œÂ·ì˜í™” ì¶”ì²œ (ì´ë¯¸ì§€ ì•ˆì •í™” ë²„ì „)")
st.write("ì´ë¯¸ì§€ ì•ˆ ëœ¨ëŠ” ë¬¸ì œë¥¼ ì¤„ì´ë ¤ê³  ì—¬ëŸ¬ API/ë°©ë²•ìœ¼ë¡œ í‘œì§€Â·í¬ìŠ¤í„°ë¥¼ ì‹œë„í•´ìš”. ê·¸ë˜ë„ ì•ˆ ëœ¨ë©´ ì•Œë ¤ì¤˜! ğŸ˜…")

# -------------------------
# ë°ì´í„°: MBTI -> (book_title, book_author, movie_title, movie_wiki_slug_hint)
# movie_wiki_slug_hintëŠ” ê°€ëŠ¥í•œ ìœ„í‚¤í˜ì´ì§€ ìŠ¬ëŸ¬ê·¸ ì˜ˆì‹œ(ì—†ìœ¼ë©´ ì˜í™” ì œëª©)
# -------------------------
mbti_media = {
    "ISTJ": ("Demian", "Hermann Hesse", "Inception", "Inception_(film)"),
    "ISFJ": ("Little Women", "Louisa May Alcott", "Frozen", "Frozen_(2013_film)"),
    "INFJ": ("The Alchemist", "Paulo Coelho", "About Time", "About_Time_(2013_film)"),
    "INTJ": ("Sapiens", "Yuval Noah Harari", "Interstellar", "Interstellar"),
    "ISTP": ("Momo", "Michael Ende", "The Bourne Identity", "The_Bourne_Identity_(film)"),
    "ISFP": ("Almond", "Son Won-pyung", "La La Land", "La_La_Land"),
    "INFP": ("Harry Potter and the Sorcerer's Stone", "J. K. Rowling", "WALLÂ·E", "WALL-E"),
    "INTP": ("Cosmos", "Carl Sagan", "The Social Network", "The_Social_Network"),
    "ESTP": ("Silent Spring", "Rachel Carson", "Avatar", "Avatar_(2009_film)"),
    "ESFP": ("The Midnight Library", "Matt Haig", "Mamma Mia!", "Mamma_Mia!"),
    "ENFP": ("The Courage to Be Disliked", "Ichiro Kishimi", "Zootopia", "Zootopia"),
    "ENTP": ("Guns, Germs, and Steel", "Jared Diamond", "Iron Man", "Iron_Man_(2008_film)"),
    "ESTJ": ("Trend Korea", "Various", "Moneyball", "Moneyball"),
    "ESFJ": ("The Art of Loving", "Erich Fromm", "The Intern", "The_Intern_(2015_film)"),
    "ENFJ": ("Justice: What's the Right Thing to Do?", "Michael J. Sandel", "Good Will Hunting", "Good_Will_Hunting"),
    "ENTJ": ("The One Thing", "Gary Keller", "The Dark Knight", "The_Dark_Knight_(film)"),
}

# ì•ˆì „í•œ placeholder (ì ë‹¹íˆ ë³´ì´ëŠ” ì´ë¯¸ì§€)
PLACEHOLDER = "https://via.placeholder.com/300x450?text=No+Image"

# -------------------------
# ë„¤íŠ¸ì›Œí¬ í—¬í¼ (User-Agent, timeout)
# -------------------------
def urlopen_json(url: str, timeout: int = 8) -> Optional[dict]:
    """ì£¼ì–´ì§„ URLì— GET ìš”ì²­ -> JSON decode. ì‹¤íŒ¨ ì‹œ None ë°˜í™˜."""
    try:
        req = urllib.request.Request(url, headers={"User-Agent": "Mozilla/5.0 (Streamlit App)"})
        with urllib.request.urlopen(req, timeout=timeout) as resp:
            raw = resp.read()
            return json.loads(raw.decode("utf-8"))
    except Exception:
        return None

def urlopen_bytes(url: str, timeout: int = 8) -> Optional[bytes]:
    """ì´ë¯¸ì§€ ë“± ë°”ì´íŠ¸ë¡œ ê°€ì ¸ì˜¤ê³  ì‹¶ì€ ê²½ìš°(ë””ë²„ê·¸ìš©). ì‹¤íŒ¨ ì‹œ None."""
    try:
        req = urllib.request.Request(url, headers={"User-Agent": "Mozilla/5.0 (Streamlit App)"})
        with urllib.request.urlopen(req, timeout=timeout) as resp:
            return resp.read()
    except Exception:
        return None

# -------------------------
# ì±… í‘œì§€ ì°¾ê¸°: Google Books -> Open Library
# -------------------------
@st.cache_data(show_spinner=False)
def get_book_cover_google(title: str, author: Optional[str] = None) -> Optional[str]:
    """Google Books APIë¡œ thumbnail ì°¾ê¸°"""
    try:
        q = f"intitle:{title}"
        if author:
            q += f"+inauthor:{author}"
        q = urllib.parse.quote(q)
        url = f"https://www.googleapis.com/books/v1/volumes?q={q}&maxResults=8"
        data = urlopen_json(url)
        if not data:
            return None
        # ìš°ì„ ìˆœìœ„: volumeInfo.imageLinks.thumbnail -> smallThumbnail
        for item in data.get("items", []):
            info = item.get("volumeInfo", {})
            imgs = info.get("imageLinks", {})
            # thumbnail ìì£¼ ì¡´ì¬
            thumb = imgs.get("thumbnail") or imgs.get("smallThumbnail")
            if thumb:
                # httpsë¡œ í†µì¼
                return thumb.replace("http://", "https://")
    except Exception:
        return None
    return None

@st.cache_data(show_spinner=False)
def get_book_cover_openlibrary(title: str, author: Optional[str] = None) -> Optional[str]:
    """
    OpenLibrary ê²€ìƒ‰: search.json?q=title+author -> use cover_i -> https://covers.openlibrary.org/b/id/{cover_i}-L.jpg
    This is a robust fallback when Google Books fails.
    """
    try:
        q = title
        if author:
            q += " " + author
        q = urllib.parse.quote(q)
        url = f"https://openlibrary.org/search.json?title={q}&limit=8"
        data = urlopen_json(url)
        if not data:
            return None
        docs = data.get("docs", [])
        for d in docs:
            cover_id = d.get("cover_i")
            if cover_id:
                return f"https://covers.openlibrary.org/b/id/{cover_id}-L.jpg"
        # ì‹œë„ 2: general search
        url2 = f"https://openlibrary.org/search.json?q={urllib.parse.quote(title)}&limit=8"
        data2 = urlopen_json(url2)
        if data2:
            for d in data2.get("docs", []):
                if d.get("cover_i"):
                    return f"https://covers.openlibrary.org/b/id/{d['cover_i']}-L.jpg"
    except Exception:
        return None
    return None

def get_book_image(title: str, author: Optional[str] = None) -> str:
    """ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„í•´ì„œ í‘œì§€ URL ë°˜í™˜. ì‹¤íŒ¨í•˜ë©´ PLACEHOLDER ë°˜í™˜."""
    # 1) Google Books (title+author)
    img = get_book_cover_google(title, author)
    if img:
        return img
    # 2) Google Books (title only)
    img = get_book_cover_google(title, None)
    if img:
        return img
    # 3) OpenLibrary (title+author)
    img = get_book_cover_openlibrary(title, author)
    if img:
        return img
    # 4) OpenLibrary (title only)
    img = get_book_cover_openlibrary(title, None)
    if img:
        return img
    # ì‹¤íŒ¨
    return PLACEHOLDER

# -------------------------
# ì˜í™” í¬ìŠ¤í„° ì°¾ê¸°: Wikipedia REST summary ì‹œë„ (en/ko), ë‹¤ì–‘í•œ ìŠ¬ëŸ¬ê·¸ í˜•ì‹ ì‹œë„
# -------------------------
@st.cache_data(show_spinner=False)
def try_wikipedia_summary_image(lang: str, page_slug: str) -> Optional[str]:
    """
    Wikipedia REST API summary endpoint:
    https://{lang}.wikipedia.org/api/rest_v1/page/summary/{slug}
    returns JSON that may include 'originalimage' or 'thumbnail'
    """
    try:
        slug = urllib.parse.quote(page_slug)
        url = f"https://{lang}.wikipedia.org/api/rest_v1/page/summary/{slug}"
        data = urlopen_json(url)
        if not data:
            return None
        # originalimage has higher-res
        oi = data.get("originalimage")
        if oi and oi.get("source"):
            return oi["source"]
        thumb = data.get("thumbnail")
        if thumb and thumb.get("source"):
            return thumb["source"]
    except Exception:
        return None
    return None

def generate_wikipedia_candidates(title: str, hint_slug: Optional[str] = None):
    """
    ê°€ëŠ¥í•œ wiki í˜ì´ì§€ slug í›„ë³´ë“¤ì„ ë°˜í™˜.
    ì‹œë„ ìˆœì„œ: hint_slug, title, title + ' (film)', title + ' (movie)', title with underscores
    """
    candidates = []
    if hint_slug:
        candidates.append(hint_slug)
    # raw title variants
    candidates.append(title)
    candidates.append(title.replace(" ", "_"))
    candidates.append(f"{title}_(film)")
    candidates.append(f"{title}_(movie)")
    # also try removing punctuation (basic)
    cleaned = "".join(ch for ch in title if ch.isalnum() or ch.isspace())
    if cleaned and cleaned != title:
        candidates.append(cleaned)
        candidates.append(cleaned.replace(" ", "_"))
        candidates.append(f"{cleaned}_(film)")
    # unique preserving order
    seen = set()
    out = []
    for c in candidates:
        if c and c not in seen:
            seen.add(c)
            out.append(c)
    return out

def get_movie_image(title: str, hint_slug: Optional[str] = None) -> str:
    """
    ë‹¤êµ­ì–´(ì˜ì–´, í•œêµ­ì–´) ìœ„í‚¤ ìš”ì•½ì„ ì—¬ëŸ¬ í›„ë³´ë¡œ ì‹œë„í•´ì„œ í¬ìŠ¤í„° URL ì–»ê¸°.
    ì‹¤íŒ¨í•˜ë©´ PLACEHOLDER ë°˜í™˜.
    """
    # í›„ë³´ ìŠ¬ëŸ¬ê·¸
    candidates = generate_wikipedia_candidates(title, hint_slug)
    # languages to try (en then ko)
    langs = ["en", "ko"]
    for lang in langs:
        for slug in candidates:
            img = try_wikipedia_summary_image(lang, slug)
            if img:
                return img
    # ë§ˆì§€ë§‰ìœ¼ë¡œ, ê°„ë‹¨íˆ ê²€ìƒ‰ APIë¡œ ê°€ì¥ ìœ ë ¥í•œ í˜ì´ì§€ë§Œ ì‹œë„í•´ë³´ëŠ” ë°©ë²•(English opensearch)
    try:
        search_q = urllib.parse.quote(title)
        opensearch_url = f"https://en.wikipedia.org/w/api.php?action=opensearch&search={search_q}&limit=5&format=json"
        data = urlopen_json(opensearch_url)
        if data and isinstance(data, list) and len(data) >= 2:
            # data[1]ëŠ” ì œëª© ë¦¬ìŠ¤íŠ¸
            for candidate_title in data[1]:
                # convert to slug
                slug = candidate_title.replace(" ", "_")
                img = try_wikipedia_summary_image("en", slug)
                if img:
                    return img
    except Exception:
        pass
    # ì‹¤íŒ¨
    return PLACEHOLDER

# -------------------------
# ê°„ë‹¨í•œ í•œì¤„ ë¦¬ë·° ìƒì„±ê¸° (ê°™ì€ í†¤ ìœ ì§€)
# -------------------------
def gen_book_one_liner(mbti: str, title: str) -> str:
    if mbti.startswith("IN") or mbti in ("INTJ","INTP"):
        return f"ã€{title}ã€ â€” ìƒê°ì„ ë„“í˜€ì£¼ëŠ” ì±…ì´ë¼ ê¹Šì´ ëª°ë‘í•˜ê¸° ì¢‹ì•„. âœ¨"
    if mbti.startswith("IS") or mbti.startswith("ES"):
        return f"ã€{title}ã€ â€” ê°ì„±ì´ë‘ ê³µê°ì´ ì‚´ì•„ìˆëŠ” í¸ì•ˆí•œ ì´ì•¼ê¸°ì•¼. ğŸ’›"
    if mbti.startswith("EN") or mbti in ("ENTJ","ENTP"):
        return f"ã€{title}ã€ â€” ìƒˆë¡œìš´ ê´€ì ê³¼ ì—ë„ˆì§€ë¥¼ ì£¼ëŠ” ì¶”ì²œì‘! ğŸ”¥"
    return f"ã€{title}ã€ â€” ì¬ë°Œê³  ë§ˆìŒì— ë‚¨ëŠ” ì‘í’ˆì´ì•¼. ğŸ“–"

def gen_movie_one_liner(mbti: str, title: str) -> str:
    if mbti in ("INTJ","INTP","ENTP"):
        return f"ã€{title}ã€ â€” ë‘ë‡Œ í’€ê°€ë™í•´ì„œ ë³´ë©´ ë” ì¬ë¯¸ìˆì–´! ğŸ§©"
    if mbti.startswith("IS") or mbti.startswith("IN"):
        return f"ã€{title}ã€ â€” ê°ì„±ì  ì—¬ìš´ì´ í° ì˜í™”ì•¼. ğŸï¸"
    if mbti.startswith("ES") or mbti.startswith("EN"):
        return f"ã€{title}ã€ â€” í…ì…˜ ë†’ì€ ì¥ë©´ì´ ë§ì•„ì„œ ì‹ ë‚˜ê²Œ ë³¼ ìˆ˜ ìˆì–´! ğŸ”¥"
    return f"ã€{title}ã€ â€” ëª°ì…ë„ ë†’ì€ ì‘í’ˆì´ë¼ ì¶”ì²œí•´. ğŸ¿"

# -------------------------
# UI
# -------------------------
selected_mbti = st.selectbox("ğŸ‘‰ MBTI ì„ íƒ!", sorted(mbti_media.keys()))
if selected_mbti:
    book_title, book_author, movie_title, movie_hint = mbti_media[selected_mbti]
    st.markdown(f"## âœ¨ {selected_mbti} ì¶”ì²œ ì½˜í…ì¸ ")

    col1, col2 = st.columns([1, 1])

    # BOOK
    with col1:
        st.subheader("ğŸ“š ì±…")
        st.write(f"**{book_title}** â€” _{book_author}_")
        st.caption("í‘œì§€ë¥¼ ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ ì°¾ì•„ì˜¤ê³  ìˆì–´ìš”... (GoogleBooks â†’ OpenLibrary)")

        book_img = get_book_image(book_title, book_author)
        st.image(book_img, use_column_width=True)
        st.write(gen_book_one_liner(selected_mbti, book_title))

        # ë””ë²„ê·¸ìš©: ì§ì ‘ ì´ë¯¸ì§€ URL í™•ì¸/ìˆ˜ì • ê°€ëŠ¥ (ì‚¬ìš©ìì—ê²Œ ë³´ì´ê²Œ ì„ íƒì ìœ¼ë¡œ)
        if st.checkbox("í‘œì§€ URL ì§ì ‘ ë³´ê¸°/ìˆ˜ì • (ë””ë²„ê·¸ìš©)"):
            url_in = st.text_input("í‘œì§€ URL (ìˆ˜ì •í•˜ë ¤ë©´ ë¶™ì—¬ë„£ê¸°)", value=book_img)
            if url_in:
                st.image(url_in, use_column_width=True)

    # MOVIE
    with col2:
        st.subheader("ğŸ¬ ì˜í™”")
        st.write(f"**{movie_title}**")
        st.caption("í¬ìŠ¤í„°ë¥¼ ì—¬ëŸ¬ ìœ„í‚¤/ìŠ¬ëŸ¬ê·¸ë¡œ ì‹œë„ ì¤‘ (en/ko ìœ„í‚¤)")

        movie_img = get_movie_image(movie_title, movie_hint)
        st.image(movie_img, use_column_width=True)
        st.write(gen_movie_one_liner(selected_mbti, movie_title))

        if st.checkbox("í¬ìŠ¤í„° URL ì§ì ‘ ë³´ê¸°/ìˆ˜ì • (ë””ë²„ê·¸ìš©)", key="movie_debug"):
            url_in2 = st.text_input("í¬ìŠ¤í„° URL (ìˆ˜ì •í•˜ë ¤ë©´ ë¶™ì—¬ë„£ê¸°)", value=movie_img, key="movie_url_input")
            if url_in2:
                st.image(url_in2, use_column_width=True)

    st.write("---")
    st.info("ì´ë¯¸ì§€ê°€ ì—¬ì „íˆ ì•ˆ ëœ¨ë©´ ì•Œë ¤ì¤˜! ì œëª©-ì €ì(ë˜ëŠ” ì˜í™” í•œê¸€/ì˜ì–´ ì œëª©)ì„ ì•Œë ¤ì£¼ë©´ ë‚´ê°€ ìŠ¬ëŸ¬ê·¸ë¥¼ ì§ì ‘ ë§¤í•‘í•´ì¤„ê²Œ ğŸ˜Š")

# -------------------------
# ë
# -------------------------
